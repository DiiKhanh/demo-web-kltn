import streamlit as st
import os
import sys
import tempfile
import shutil
import zipfile
import time
from pathlib import Path
import pandas as pd
import plotly.express as px
import importlib  # Required for dynamic imports

# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n
current_dir = os.path.dirname(os.path.abspath(__file__))
# Modified: Use current_dir since team_code_densenet.py is in the same directory as App.py
sys.path.append(current_dir)

# --- CORRECTED: Ensure helper_code functions are imported ---
try:
    from helper_code import load_text_file, get_variable, get_cpc
except ImportError as e:
    st.error(f"Kh√¥ng th·ªÉ import helper_code: {e}. ƒê·∫£m b·∫£o helper_code.py t·ªìn t·∫°i trong {current_dir}.")
    st.stop()

# --- Dynamic Importer with Debug Output ---
def get_model_functions(model_module_name):
    """
    Dynamically imports load_challenge_models and run_challenge_models
    from the specified model module.
    """
    # st.write(f"Debug: Attempting to import module '{model_module_name}'")
    # st.write(f"Debug: Current sys.path: {sys.path}")
    try:
        module = importlib.import_module(model_module_name)
        st.write(f"Debug: Successfully imported module '{model_module_name}'")
        load_models_func = getattr(module, 'load_challenge_models')
        run_models_func = getattr(module, 'run_challenge_models')
        st.write(f"Debug: Found functions in '{model_module_name}'")
        return load_models_func, run_models_func
    except ImportError as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ import module: {model_module_name}. Error: {str(e)}. ƒê·∫£m b·∫£o file {model_module_name}.py t·ªìn t·∫°i trong {current_dir}.")
        return None, None
    except AttributeError as e:
        st.error(f"‚ùå Module {model_module_name} thi·∫øu h√†m 'load_challenge_models' ho·∫∑c 'run_challenge_models'. Error: {str(e)}")
        return None, None
    except Exception as e:
        st.error(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh khi import t·ª´ {model_module_name}: {str(e)}")
        return None, None

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="EEG Prediction App",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
.main-header {
    font-size: 3rem;
    color: #1f77b4;
    text-align: center;
    margin-bottom: 2rem;
}
.prediction-result {
    padding: 1rem;
    border-radius: 10px;
    text-align: center;
    font-size: 1.5rem;
    font-weight: bold;
    margin: 1rem 0;
}
.good-result {
    background-color: #d4edda;
    color: #155724;
    border: 2px solid #28a745;
}
.poor-result {
    background-color: #f8d7da;
    color: #721c24;
    border: 2px solid #dc3545;
}
.debug-section {
    border: 1px solid #e9ecef;
    border-radius: 5px;
    padding: 1rem;
    background-color: #f8f9fa;
    margin: 1rem 0;
}
</style>
""", unsafe_allow_html=True)

class EEGPredictor:
    def __init__(self):
        self.models = None
        self.is_loaded = False
        self.current_model_name = None
        self.load_challenge_models_dynamic = None
        self.run_challenge_models_dynamic = None

    def set_model_functions(self, model_name, load_func, run_func):
        if self.current_model_name != model_name:
            self.models = None
            self.is_loaded = False
            self.current_model_name = model_name
        self.load_challenge_models_dynamic = load_func
        self.run_challenge_models_dynamic = run_func

    def load_models(self, model_physical_folder):
        if not self.load_challenge_models_dynamic:
            st.error("‚ùå H√†m t·∫£i model ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p. Vui l√≤ng ch·ªçn model h·ª£p l·ªá.")
            return False
        try:
            if not self.is_loaded:
                with st.spinner(f"ƒêang t·∫£i models cho {self.current_model_name} t·ª´ {model_physical_folder}..."):
                    self.models = self.load_challenge_models_dynamic(model_physical_folder, verbose=1)
                    self.is_loaded = True
                st.success(f"‚úÖ Models cho {self.current_model_name} t·ª´ {model_physical_folder} ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
            else:
                st.info(f"Models cho {self.current_model_name} ƒë√£ ƒë∆∞·ª£c t·∫£i.")
            return True
        except Exception as e:
            st.error(f"‚ùå L·ªói khi t·∫£i models cho {self.current_model_name} t·ª´ {model_physical_folder}: {str(e)}")
            self.is_loaded = False
            return False

    def predict_single_patient(self, temp_data_folder, patient_id, model_physical_folder):
        if not self.run_challenge_models_dynamic:
            st.error("‚ùå H√†m predict model ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p. Vui l√≤ng ch·ªçn model h·ª£p l·ªá.")
            return None, None, None
        try:
            if not self.is_loaded:
                st.warning(f"Models cho {self.current_model_name} ch∆∞a ƒë∆∞·ª£c t·∫£i. ƒêang th·ª≠ t·∫£i...")
                if not self.load_models(model_physical_folder):
                    return None, None, None

            patient_folder = os.path.join(temp_data_folder, patient_id)
            if not os.path.exists(patient_folder):
                st.error(f"Kh√¥ng t√¨m th·∫•y folder patient: {patient_id}")
                return None, None, None
            files_in_folder = os.listdir(patient_folder)
            hea_files = [f for f in files_in_folder if f.endswith('.hea')]
            mat_files = [f for f in files_in_folder if f.endswith('.mat')]
            if not hea_files or not mat_files:
                st.error(f"Thi·∫øu file .hea ho·∫∑c .mat trong folder {patient_id}")
                return None, None, None
            metadata_file = os.path.join(patient_folder, f"{patient_id}.txt")
            actual_outcome = None
            if os.path.exists(metadata_file):
                try:
                    meta_data = load_text_file(metadata_file)
                    actual_outcome = get_variable(meta_data, 'Outcome', str) if meta_data else None
                except Exception as e_meta:
                    st.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc outcome t·ª´ metadata file {metadata_file}: {e_meta}")
                    pass
            else:
                with open(metadata_file, 'w') as f:
                    f.write(f"Patient: {patient_id}\n")
                    f.write("Age: Unknown\n")
                    f.write("Sex: Unknown\n")
                    f.write("Outcome: Unknown\n")

            with st.spinner(f"ƒêang predict cho patient {patient_id} s·ª≠ d·ª•ng {self.current_model_name}..."):
                outcome_binary, outcome_probability = self.run_challenge_models_dynamic(
                    self.models, temp_data_folder, patient_id, verbose=0
                )
            return outcome_binary, outcome_probability, actual_outcome
        except Exception as e:
            st.error(f"L·ªói khi predict patient {patient_id} v·ªõi {self.current_model_name}: {str(e)}")
            return None, None, None

def debug_folder_structure(base_path, level=0, max_level=3):
    debug_info = []
    if level > max_level:
        return debug_info
    try:
        items = os.listdir(base_path)
        for item in items:
            item_path = os.path.join(base_path, item)
            indent = "  " * level
            if os.path.isdir(item_path):
                debug_info.append(f"{indent}üìÅ {item}/")
                try:
                    files = os.listdir(item_path)
                    hea_files = [f for f in files if f.endswith('.hea')]
                    mat_files = [f for f in files if f.endswith('.mat')]
                    if hea_files or mat_files:
                        debug_info.append(f"{indent}  ‚Üí .hea files: {len(hea_files)}, .mat files: {len(mat_files)}")
                    if level < max_level:
                        sub_debug = debug_folder_structure(item_path, level + 1, max_level)
                        debug_info.extend(sub_debug)
                except PermissionError:
                    debug_info.append(f"{indent}  ‚Üí (Permission denied)")
            else:
                file_ext = os.path.splitext(item)[1]
                if file_ext in ['.hea', '.mat', '.txt']:
                    debug_info.append(f"{indent}üìÑ {item}")
    except Exception as e:
        debug_info.append(f"{indent}‚ùå Error reading {base_path}: {str(e)}")
    return debug_info

def extract_uploaded_files(uploaded_files, temp_dir):
    extracted_folders_map = {}
    for uploaded_file in uploaded_files:
        file_name = uploaded_file.name
        file_path = os.path.join(temp_dir, file_name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        if file_name.endswith('.zip'):
            try:
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    zip_ref.extractall(temp_dir)
                    extracted_folders_map[temp_dir] = True
                    st.success(f"‚úÖ ƒê√£ gi·∫£i n√©n: {file_name} v√†o {temp_dir}")
            except Exception as e:
                st.error(f"‚ùå L·ªói khi gi·∫£i n√©n {file_name}: {str(e)}")
    return list(extracted_folders_map.keys())

def find_patient_folders(base_path, debug_mode=False):
    patient_folders_dict = {}
    if debug_mode:
        st.info(f"üîç Scanning directory: {base_path}")
        st.markdown("**üìÅ Folder Structure (during find_patient_folders):**")
        debug_info = debug_folder_structure(base_path, max_level=2)
        if debug_info:
            for line in debug_info[:30]:
                st.text(line)
            if len(debug_info) > 30:
                st.text(f"... and {len(debug_info) - 30} more items")
    for root, dirs, files in os.walk(base_path):
        hea_files = [f for f in files if f.endswith('.hea')]
        mat_files = [f for f in files if f.endswith('.mat')]
        if debug_mode and (hea_files or mat_files or dirs):
            relative_path = os.path.relpath(root, base_path)
        if hea_files and mat_files:
            folder_name = os.path.basename(root)
            if folder_name not in patient_folders_dict:
                if root != base_path or (root == base_path and not any(os.path.isdir(os.path.join(root, d)) for d in dirs if d != "prediction_input_data")):
                    patient_folders_dict[folder_name] = root
                    if debug_mode:
                        st.success(f"‚úÖ Tentatively found patient: {folder_name} at {root}")
    patient_folders = list(patient_folders_dict.items())
    if debug_mode and not patient_folders:
        st.warning(f"No patient folders found directly in {base_path} or its subdirectories.")
    return patient_folders

def main():
    # st.markdown('<h1 class="main-header">üß† EEG Prediction System</h1>', unsafe_allow_html=True)
    # HEADER
    st.markdown(
    """
    <style>
    .header-container {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 10px 20px;
        background-color: #1e1e1e;
        border-bottom: 2px solid #444;
        color: #ffffff;
    }
    .left-section, .right-section {
        display: flex;
        align-items: center;
    }
    .left-section img, .right-section img {
        height: 80px;
        margin-right: 15px;
        margin-left: 15px;
        filter: brightness(0.9);
    }
    .left-text, .right-text {
        font-size: 18px;
        font-weight: bold;
        line-height: 1.4;
        color: #ffffff;
    }
    </style>
    <div class="header-container">
        <div class="left-section">
            <img src="https://www.uit.edu.vn/sites/vi/files/images/Logos/Logo_UIT_Web_Transparent.png" alt="Logo Tr∆∞·ªùng">
            <div class="left-text">
                TR∆Ø·ªúNG ƒê·∫†I H·ªåC C√îNG NGH·ªÜ TH√îNG TIN - ƒêHQG-HCM<br>
                KHOA H·ªÜ TH·ªêNG TH√îNG TIN
            </div>
        </div>
        <div class="right-section">
            <div class="right-text">
                D·ª∞ ƒêO√ÅN KH·∫¢ NƒÇNG PH·ª§C H·ªíI TH·∫¶N KINH ·ªû B·ªÜNH NH√ÇN H√îN M√ä SAU NG·ª™NG TIM<br>
                S·ª¨ D·ª§NG C√ÅC M√î H√åNH H·ªåC S√ÇU
            </div>
            <img src="https://cdn-icons-png.flaticon.com/512/9851/9851782.png" alt="Logo ƒê·ªÅ t√†i">
        </div>
    </div>
    """,
    unsafe_allow_html=True
    )
    # HEADER
    st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh")
    debug_mode = st.sidebar.checkbox("üêõ Debug Mode", value=False, help="Show detailed folder structure and debugging info")

    # --- CORRECTED: Model configuration with accurate module name for EfficientNet ---
    model_config = {
        "DenseNet-121": {"module": "team_code_densenet", "path": "models/densenet121"},
        "ResNet-50": {"module": "team_code_resnet50", "path": "models/resnet50"},
        "ConvNeXt": {"module": "team_code_convnext", "path": "models/convnext"},
        "EfficientNet-V2-S": {"module": "team_code_efficient", "path": "models/efficentnet-v2-s-72"} # Corrected module name
    }

    selected_model_display_name = st.sidebar.selectbox(
        "Ch·ªçn Model:",
        options=list(model_config.keys()),
        help="Ch·ªçn model ƒë√£ train ƒë·ªÉ s·ª≠ d·ª•ng cho prediction."
    )

    selected_model_module_name = model_config[selected_model_display_name]["module"]
    selected_model_physical_path = model_config[selected_model_display_name]["path"]

    if 'predictor' not in st.session_state:
        st.session_state.predictor = EEGPredictor()

    load_fn, run_fn = get_model_functions(selected_model_module_name)
    if load_fn and run_fn:
        st.session_state.predictor.set_model_functions(selected_model_display_name, load_fn, run_fn)
    else:
        st.sidebar.error(f"Kh√¥ng th·ªÉ t·∫£i c√°c h√†m cho model {selected_model_display_name}. Ki·ªÉm tra t√™n module '{selected_model_module_name}.py' v√† ƒë·∫£m b·∫£o file t·ªìn t·∫°i.")

    if st.sidebar.button("üîÑ T·∫£i Models", key="load_models_button"):
        if st.session_state.predictor.load_challenge_models_dynamic:
            st.session_state.predictor.load_models(selected_model_physical_path)
        else:
            st.sidebar.error("H√†m t·∫£i model ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p do l·ªói import. Vui l√≤ng ch·ªçn model h·ª£p l·ªá v√† ki·ªÉm tra th√¥ng b√°o l·ªói.")

    col1, col2 = st.columns([2, 1])
    with col1:
        st.header("üìÅ Upload EEG Data")
        st.markdown('<div>', unsafe_allow_html=True)
        st.markdown("**üìã H∆∞·ªõng d·∫´n upload:**")
        st.markdown("""
        - Upload file ZIP.
        - File ZIP ph·∫£i ch·ª©a c√°c **folder ƒë·∫∑t t√™n theo ID b·ªánh nh√¢n** (v√≠ d·ª•: 0391, 1234, patient_001).
        - M·ªói folder b·ªánh nh√¢n ph·∫£i ch·ª©a:
            - File `.hea` (header file)
            - File `.mat` (data file)
            - T√πy ch·ªçn: File `.txt` (metadata b·ªánh nh√¢n, n·∫øu c√≥ s·∫Ω ƒë·ªçc Outcome th·ª±c t·∫ø)
        - **C·∫•u tr√∫c ZIP ƒë∆∞·ª£c khuy·∫øn ngh·ªã:**
        ```
            your_data.zip
            ‚îú‚îÄ‚îÄ 0391/
            ‚îÇ   ‚îú‚îÄ‚îÄ 0391.hea
            ‚îÇ   ‚îú‚îÄ‚îÄ 0391.mat
            ‚îÇ   ‚îî‚îÄ‚îÄ (0391.txt)
            ‚îú‚îÄ‚îÄ 1234/
            ‚îÇ   ‚îú‚îÄ‚îÄ 1234.hea
            ‚îÇ   ‚îú‚îÄ‚îÄ 1234.mat
            ‚îÇ   ‚îî‚îÄ‚îÄ (1234.txt)
            ‚îî‚îÄ‚îÄ ...
        ```
        """)
        uploaded_files = st.file_uploader(
            "Ch·ªçn file ZIP ch·ª©a d·ªØ li·ªáu EEG",
            accept_multiple_files=True,
            type=['zip'],
            help="Upload file ZIP ch·ª©a c√°c folder b·ªánh nh√¢n v·ªõi file .hea v√† .mat"
        )
        st.markdown('</div>', unsafe_allow_html=True)
        if uploaded_files:
            st.success(f"‚úÖ ƒê√£ upload {len(uploaded_files)} file(s)")
            file_info = [{"T√™n File": f.name, "K√≠ch th∆∞·ªõc": f"{f.size / (1024*1024):.2f} MB", "Lo·∫°i": "ZIP Archive"} for f in uploaded_files]
            st.dataframe(pd.DataFrame(file_info), use_container_width=True)

    with col2:
        st.header("üéØ Prediction")
        if st.button("üöÄ B·∫Øt ƒë·∫ßu Predict", type="primary", use_container_width=True, key="predict_button"):
            if not uploaded_files:
                st.warning("‚ö†Ô∏è Vui l√≤ng upload files EEG tr∆∞·ªõc!")
                return

            if not st.session_state.predictor.load_challenge_models_dynamic or \
                not st.session_state.predictor.run_challenge_models_dynamic:
                st.error("‚ùå Model functions kh√¥ng ƒë∆∞·ª£c t·∫£i ƒë√∫ng c√°ch. Vui l√≤ng ki·ªÉm tra l·ª±a ch·ªçn model v√† th√¥ng b√°o l·ªói ·ªü sidebar.")
                return

            if not st.session_state.predictor.is_loaded:
                st.warning(f"‚ö†Ô∏è Models cho {st.session_state.predictor.current_model_name} ch∆∞a ƒë∆∞·ª£c t·∫£i! ƒêang th·ª≠ t·∫£i...")
                if not st.session_state.predictor.load_models(selected_model_physical_path):
                    st.error("Kh√¥ng th·ªÉ t·∫£i models. Prediction b·ªã h·ªßy.")
                    return

            with tempfile.TemporaryDirectory() as temp_dir:
                if debug_mode: st.info(f"üîß Debug: Using temp directory: {temp_dir}")
                # st.info("üì¶ ƒêang x·ª≠ l√Ω files upload...") # Can be noisy
                base_extraction_path = temp_dir
                for uploaded_file in uploaded_files:
                    file_path = os.path.join(base_extraction_path, uploaded_file.name)
                    with open(file_path, "wb") as f: f.write(uploaded_file.getbuffer())
                    if uploaded_file.name.endswith('.zip'):
                        try:
                            with zipfile.ZipFile(file_path, 'r') as zip_ref:
                                zip_ref.extractall(base_extraction_path)
                                # st.success(f"‚úÖ ƒê√£ gi·∫£i n√©n: {uploaded_file.name} v√†o {base_extraction_path}")
                        except Exception as e:
                            st.error(f"‚ùå L·ªói khi gi·∫£i n√©n {uploaded_file.name}: {str(e)}")
                            continue
                    else: st.warning(f"Skipping non-ZIP file: {uploaded_file.name}")

                if debug_mode:
                    st.markdown(f"### üêõ Debug: Structure of temp_dir after extraction: {base_extraction_path}")
                    debug_tree = debug_folder_structure(base_extraction_path, max_level=2)
                    for line in debug_tree: st.text(line)

                st.info("üîç ƒêang t√¨m patient folders...")
                all_patient_folders_info = find_patient_folders(base_extraction_path, debug_mode=debug_mode)

                if not all_patient_folders_info:
                    st.error("‚ùå Kh√¥ng t√¨m th·∫•y patient data h·ª£p l·ªá trong files upload.")
                    if debug_mode:
                        st.markdown("### üêõ Debug Help for No Patients Found:")
                        st.markdown(f"""
                        **Ki·ªÉm tra c√°c v·∫•n ƒë·ªÅ sau:**
                        1. File ZIP c√≥ th·ª±c s·ª± ch·ª©a c√°c **folder con** kh√¥ng? (v√≠ d·ª•: `patient_ID_1/`, `patient_ID_2/`)
                        2. M·ªói folder con (v√≠ d·ª•: `patient_ID_1/`) c√≥ ch·ª©a c·∫£ file `.hea` v√† `.mat` kh√¥ng?
                        3. T√™n file c√≥ ƒë√∫ng ƒë·ªãnh d·∫°ng kh√¥ng?
                        4. C·∫•u tr√∫c th∆∞ m·ª•c c√≥ kh·ªõp v·ªõi h∆∞·ªõng d·∫´n kh√¥ng?
                        **C·∫•u tr√∫c th∆∞ m·ª•c ƒë∆∞·ª£c qu√©t trong `{base_extraction_path}`:**
                        V√≠ d·ª•: `{base_extraction_path}/0391/0391.hea` v√† `{base_extraction_path}/0391/0391.mat`
                        """)
                    return

                st.success(f"‚úÖ T√¨m th·∫•y {len(all_patient_folders_info)} patient(s).")
                if debug_mode:
                    st.markdown("### üìã Found Patients for Prediction:")
                    for patient_id, patient_original_path in all_patient_folders_info:
                        st.text(f"  üë§ {patient_id} (source: {patient_original_path})")

                results = []
                progress_bar = st.progress(0)
                status_text = st.empty()
                prediction_input_dir = os.path.join(temp_dir, "prediction_input_data")
                os.makedirs(prediction_input_dir, exist_ok=True)

                for i, (patient_id, patient_original_path) in enumerate(all_patient_folders_info):
                    progress_bar.progress((i + 1) / len(all_patient_folders_info))
                    status_text.text(f"üîÑ ƒêang predict cho Patient {patient_id} ({i+1}/{len(all_patient_folders_info)})")
                    temp_patient_run_folder = os.path.join(prediction_input_dir, patient_id)
                    os.makedirs(temp_patient_run_folder, exist_ok=True)
                    try:
                        for item_name in os.listdir(patient_original_path):
                            src_item = os.path.join(patient_original_path, item_name)
                            dst_item = os.path.join(temp_patient_run_folder, item_name)
                            if os.path.isfile(src_item): shutil.copy2(src_item, dst_item)
                        if debug_mode:
                            copied_files = os.listdir(temp_patient_run_folder)
                            # st.text(f"  Copied {len(copied_files)} files to {temp_patient_run_folder} for patient {patient_id}")
                    except Exception as e:
                        st.error(f"Error copying files for {patient_id}: {str(e)}")
                        results.append({'Patient ID': patient_id, 'Prediction': 'Error - File Prep', 'Actual': "N/A"})
                        continue
                    
                    outcome_binary, outcome_prob, actual_outcome = st.session_state.predictor.predict_single_patient(
                        prediction_input_dir, patient_id, selected_model_physical_path
                    )

                    if outcome_binary is not None:
                        results.append({
                            'Patient ID': patient_id,
                            'Prediction': 'Good' if outcome_binary == 0 else 'Poor',
                            # 'Probability': f"{outcome_prob:.4f}" if outcome_prob is not None else "N/A",
                            'Actual': actual_outcome if actual_outcome else "Unknown"
                        })
                    else:
                        results.append({
                            'Patient ID': patient_id,
                            'Prediction': 'Error - Prediction Failed',
                            # 'Probability': "N/A",
                            'Actual': actual_outcome if actual_outcome else "N/A" # Keep actual if read
                        })

                progress_bar.empty()
                status_text.empty()

                if results:
                    st.header("üìä K·∫øt Qu·∫£ Prediction")
                    results_df = pd.DataFrame(results)
                    st.dataframe(results_df, use_container_width=True)
                    st.subheader("üìà Ph√¢n ph·ªëi K·∫øt qu·∫£ Prediction")
                    prediction_counts = results_df['Prediction'].value_counts().reset_index()
                    prediction_counts.columns = ['Prediction', 'Count']
                    color_map = {'Good': '#28a745', 'Poor': '#dc3545', 'Error - Prediction Failed': '#ffc107', 'Error - File Prep': '#6c757d'}
                    for pred_type in prediction_counts['Prediction']:
                        if pred_type not in color_map: color_map[pred_type] = '#007bff'
                    fig = px.bar(prediction_counts, x='Prediction', y='Count', color='Prediction', color_discrete_map=color_map, title="S·ªë l∆∞·ª£ng theo t·ª´ng lo·∫°i Prediction", labels={'Count': 'S·ªë l∆∞·ª£ng b·ªánh nh√¢n', 'Prediction': 'K·∫øt qu·∫£ D·ª± ƒëo√°n'})
                    fig.update_layout(xaxis_title="K·∫øt qu·∫£ D·ª± ƒëo√°n", yaxis_title="S·ªë l∆∞·ª£ng b·ªánh nh√¢n")
                    st.plotly_chart(fig, use_container_width=True)
                    st.subheader("üí° K·∫øt qu·∫£ chi ti·∫øt t·ª´ng Patient")
                    for _, row in results_df.iterrows():
                        # patient_id, prediction, probability = row['Patient ID'], row['Prediction'], row['Probability']
                        # if prediction == 'Good': st.markdown(f'''<div class="prediction-result good-result">üë§ {patient_id}: {prediction} (Prob: {probability})</div>''', unsafe_allow_html=True)
                        # elif prediction == 'Poor': st.markdown(f'''<div class="prediction-result poor-result">üë§ {patient_id}: {prediction} (Prob: {probability})</div>''', unsafe_allow_html=True)
                        patient_id, prediction = row['Patient ID'], row['Prediction']
                        if prediction == 'Good': 
                            st.markdown(f'''<div class="prediction-result good-result">üë§ {patient_id}: {prediction}</div>''', unsafe_allow_html=True)
                        elif prediction == 'Poor': 
                            st.markdown(f'''<div class="prediction-result poor-result">üë§ {patient_id}: {prediction}</div>''', unsafe_allow_html=True)
                        else: st.error(f"üë§ {patient_id}: {prediction}")
                    good_count = sum(1 for r in results if r['Prediction'] == 'Good')
                    poor_count = sum(1 for r in results if r['Prediction'] == 'Poor')
                    error_count = sum(1 for r in results if 'Error' in r['Prediction'])
                    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
                    with col_stat1: st.metric("Total Patients", len(results))
                    with col_stat2: st.metric("Good Outcomes", good_count)
                    with col_stat3: st.metric("Poor Outcomes", poor_count)
                    with col_stat4: st.metric("Errors", error_count)
                    csv_data = results_df.to_csv(index=False).encode('utf-8')
                    st.download_button(label="üì• Download Results (CSV)", data=csv_data, file_name=f"eeg_predictions_{selected_model_display_name.replace('/','_').replace(' ','_')}_{int(time.time())}.csv", mime="text/csv")
                else:
                    st.error("‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ prediction n√†o!")

    st.markdown("---")
    st.markdown(
    """
    <style>
    .header-container {
        display: flex;
        justify-content: space-between;
        margin-bottom: 20px;
    }
    .left-column {
        flex: 1;
        text-align: left;
        padding: 10px;
    }
    .middle-column {
        flex: 1;
        text-align: center;
        padding: 10px;
    }
    .right-column {
        flex: 1;
        text-align: right;
        padding: 10px;
    }
    </style>
    """,
    unsafe_allow_html=True
    )
    st.markdown(
    """
    <div class="header-container">
        <div class="left-column">
            D·ª∞ ƒêO√ÅN KH·∫¢ NƒÇNG PH·ª§C H·ªíI TH·∫¶N KINH ·ªû B·ªÜNH NH√ÇN H√îN M√ä SAU NG·ª™NG TIM S·ª¨ D·ª§NG C√ÅC M√î H√åNH H·ªåC S√ÇU<br>
            TP.HCM, th√°ng 6 nƒÉm 2025
        </div>
        <div class="middle-column">
            Nh√≥m sinh vi√™n th·ª±c hi·ªán:<br>
            L∆ØU HI·∫æU NG√ÇN ‚Äì 21520358<br>
            PH·∫†M DUY KH√ÅNH - 21522211
        </div>
        <div class="right-column">
            GI·∫¢NG VI√äN H∆Ø·ªöNG D·∫™N<br>
            ThS. D∆Ø∆†NG PHI LONG
        </div>
    </div>
    """,
    unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()